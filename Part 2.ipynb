{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:09.606060Z",
     "start_time": "2024-06-29T09:48:04.686212Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from scipy import spatial \n",
    "import faiss\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "62f09c59a02a3b0d",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "id": "5a991f1eb012a476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:09.622047Z",
     "start_time": "2024-06-29T09:48:09.609046Z"
    }
   },
   "source": [
    "def semi_optimized_exhaustive_search(\n",
    "        index_vectors: np.ndarray,\n",
    "        query_vectors: np.ndarray,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function performs an optimized exhaustive search.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors. \n",
    "        dim: The dimensionality of the vectors.\n",
    "    Returns:\n",
    "        An array of shape (n_queries, k) containing the indices of the k nearest neighbors for each query vector.\n",
    "    \"\"\"\n",
    "    ann_lists = []\n",
    "    for query_vec in query_vectors:\n",
    "        distances = np.linalg.norm(index_vectors - query_vec, axis=1)\n",
    "        ann_lists.append(list(np.argsort(distances)[:k]))\n",
    "    return np.array(ann_lists)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a8ef475c717fbe2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:09.637578Z",
     "start_time": "2024-06-29T09:48:09.625048Z"
    }
   },
   "source": [
    "def build_faiss_flatl2_index(\n",
    "        index_vectors: np.ndarray,\n",
    "        dim: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a Faiss flat L2 index.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        dim: The dimensionality of the vectors. \n",
    "    Returns:\n",
    "        A Faiss flat L2 index.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(index_vectors)\n",
    "    return index"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "1df7a2d698755a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:09.652577Z",
     "start_time": "2024-06-29T09:48:09.640586Z"
    }
   },
   "source": [
    "def faiss_search(\n",
    "        query_vectors: np.ndarray,\n",
    "        index: faiss.Index,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function uses a Faiss index to search for the k-nearest neighbors of query_vectors.\n",
    "    Args:\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors. \n",
    "        index: A Faiss index.\n",
    "        k: The number of nearest neighbors to retrieve.\n",
    "    Returns:\n",
    "        An array of shape (, ) containing the indices of the k-nearest neighbors for each query vector.\n",
    "    \"\"\"\n",
    "    distances, indices = index.search(query_vectors, k)\n",
    "    return indices"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "af14bea64023a3d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:09.668580Z",
     "start_time": "2024-06-29T09:48:09.656578Z"
    }
   },
   "source": [
    "def build_faiss_lsh_index(\n",
    "        index_vectors: np.ndarray,\n",
    "        dim: int,\n",
    "        nbits: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a Faiss LSH index.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        dim: The dimensionality of the vectors. \n",
    "        nbits: The number of bits to use in the hash.\n",
    "    Returns:\n",
    "        A Faiss LSH index.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexLSH(dim, nbits)\n",
    "    index.add(index_vectors)\n",
    "    return index"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "b4b0932dfa7d7a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:09.699575Z",
     "start_time": "2024-06-29T09:48:09.673578Z"
    }
   },
   "source": [
    "def compute_recall_at_k(\n",
    "        nn_gt: np.ndarray,\n",
    "        ann: np.ndarray,\n",
    "        k: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function computes the recall@k.\n",
    "    Args:\n",
    "        nn_gt: The ground truth nearest neighbors.\n",
    "        ann: The approximate nearest neighbors.\n",
    "        k: The number of nearest neighbors to consider.\n",
    "    Returns:\n",
    "        The recall@k.\n",
    "    \"\"\"\n",
    "    return round(sum([len(set(ann[i]) & set(nn_gt[i])) / k for i in range(len(ann))])/len(ann), 3)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "77d4be2e90ed842",
   "metadata": {},
   "source": [
    "# 2.1 -- LSH vs Naive Exhaustive Search (Regular Index Vectors)\n",
    "### You just have to run the following cells and add the following results to the report:\n",
    "* running time of the ground truth computation with semi_optimized_exhaustive_search (wall time)\n",
    "* running time of creating faiss_lsh_index (wall time)\n",
    "* running time of faiss_search over query_vectors with faiss_lsh_index (wall time)\n",
    "* recall@10 for faiss_lsh_ann"
   ]
  },
  {
   "cell_type": "code",
   "id": "b4fdbd7671405821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:09.746575Z",
     "start_time": "2024-06-29T09:48:09.702578Z"
    }
   },
   "source": [
    "query_vectors = np.load('data/query_vectors.npy')\n",
    "index_vectors = np.load('data/index_vectors.npy')\n",
    "k=10\n",
    "dim = index_vectors.shape[1]"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "65ff74d429524ffc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:28.624977Z",
     "start_time": "2024-06-29T09:48:09.749578Z"
    }
   },
   "source": [
    "%%time\n",
    "gt_nn = semi_optimized_exhaustive_search(index_vectors, query_vectors, k)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18.7 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "bd448cbdb96b1ba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:29.246598Z",
     "start_time": "2024-06-29T09:48:28.627979Z"
    }
   },
   "source": [
    "%%time\n",
    "faiss_lsh_index = build_faiss_lsh_index(index_vectors, dim, nbits=2000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.03 s\n",
      "Wall time: 600 ms\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "b0a321e6b7406267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:29.518581Z",
     "start_time": "2024-06-29T09:48:29.251581Z"
    }
   },
   "source": [
    "%%time\n",
    "faiss_lsh_ann = faiss_search(query_vectors, faiss_lsh_index, k)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.44 s\n",
      "Wall time: 254 ms\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:29.534580Z",
     "start_time": "2024-06-29T09:48:29.520580Z"
    }
   },
   "cell_type": "code",
   "source": "faiss_lsh_ann.shape",
   "id": "6edbd26c49a1c87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "e5554595c4d77a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:29.564581Z",
     "start_time": "2024-06-29T09:48:29.536581Z"
    }
   },
   "source": [
    "print(f\"recall@10 for faiss_lsh_index: {compute_recall_at_k(gt_nn, faiss_lsh_ann, k)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@10 for faiss_lsh_index: 0.138\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "ad5ca983b3a893e5",
   "metadata": {},
   "source": [
    "# 2.2 -- Custom Indexing Algorithm\n",
    "Build an indexing algorithm that satisfies the following requirements:\n",
    "* The indexing algorithm should be able to handle vectors of different dimensions\n",
    "* The running time of the indexing should be less than half of the running time of semi_optimized_exhaustive_search), reported in Section 2.1.\n",
    "* The running time of searching over the index should be less than a third (1/3) of the time of the semi_optimized_exhaustive_search function, reported in Section 2.1.\n",
    "* The performance (in terms of recall@10) of the indexing algorithm should be at least 0.8.\n",
    "\n",
    "The last three bullets should also appear in the report.\n",
    "You are allowed to add as many helper functions as you need. You cannot use faiss of scipy libraries for this task. Numpy is allowed. \n",
    "\n",
    "You can also test your algorithm with the additional two query-index sets by replacing the calls made few cells ago to:\n",
    "\n",
    "    query_vectors = np.load('data/query_vectors2.npy')\n",
    "    index_vectors = np.load('data/index_vectors2.npy')\n",
    "or:\n",
    "\n",
    "    query_vectors = np.load('data/query_vectors3.npy')\n",
    "    index_vectors = np.load('data/index_vectors3.npy')\n",
    "    \n",
    "the aforementioned requirements should also be satisfied over these two query-index sets. No need to insert the results over these two to the report."
   ]
  },
  {
   "cell_type": "code",
   "id": "8421dc36363650c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:29.596579Z",
     "start_time": "2024-06-29T09:48:29.567580Z"
    }
   },
   "source": [
    "#TODO: Write your code for 2.2.2 here\n",
    "# You are allowed to add more arguments to the functions and create more functions if needed.\n",
    "\n",
    "def update_k_means_centroids(vectors, centroids):\n",
    "    \"\"\"\n",
    "    Update the k-means centroids\n",
    "    \"\"\"\n",
    "    n_clusters = len(centroids)\n",
    "    distances = np.linalg.norm(vectors[:, np.newaxis] - centroids, axis=2)\n",
    "    labels = np.argmin(distances, axis=1)\n",
    "    new_centroids = []\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_vectors = vectors[labels == cluster_id]\n",
    "        # remove empty clusters\n",
    "        if len(cluster_vectors) > 0:\n",
    "            new_centroid = cluster_vectors.mean(axis=0) \n",
    "            new_centroids.append(new_centroid)\n",
    "        \n",
    "    return np.array(new_centroids)\n",
    "\n",
    "def separate_to_clusters(vectors, centroids):\n",
    "    \"\"\"\n",
    "    Given vectors and centroids, separate the vectors to an index based on the centroids\n",
    "    :return: The vectors divided into clusters, the vector ids divided into clusters\n",
    "    \"\"\"\n",
    "    distances = np.linalg.norm(vectors[:, np.newaxis] - centroids, axis=2)\n",
    "    labels = np.argmin(distances, axis=1)\n",
    "    clusters_vectors = {}\n",
    "    clusters_vector_ids = {}\n",
    "    for vector_id, (vector, label) in enumerate(zip(vectors, labels)):\n",
    "        if label in clusters_vectors:\n",
    "            clusters_vectors[label].append(vector)\n",
    "            clusters_vector_ids[label].append(vector_id)\n",
    "        else:\n",
    "            clusters_vectors[label] = [vector,]\n",
    "            clusters_vector_ids[label] = [vector_id,]\n",
    "            \n",
    "    for label in clusters_vectors:\n",
    "        clusters_vectors[label] = np.array(clusters_vectors[label])\n",
    "        clusters_vector_ids[label] = np.array(clusters_vector_ids[label])\n",
    "            \n",
    "    return clusters_vectors, clusters_vector_ids\n",
    "\n",
    "def initialize_k_means_pp(vectors, n_clusters):\n",
    "    \"\"\"\n",
    "    Initialize k-means-plus-plus clusters\n",
    "    \"\"\"\n",
    "    # Choose the first centroid uniformly\n",
    "    # Choose vectors to be centroids,\n",
    "    # with bigger probability the farther they are from previously chosen centroids \n",
    "    centroids = np.zeros((n_clusters, vectors.shape[1]))\n",
    "    centroids[0] = vectors[np.random.choice(vectors.shape[0])]  # Choose the first centroid randomly\n",
    "    for i in range(1, n_clusters):\n",
    "        distances = np.zeros(vectors.shape[0])\n",
    "        for j, vector in enumerate(vectors):\n",
    "            distances[j] = np.min(np.linalg.norm(vector - centroids[:i], axis=1))\n",
    "        probabilities = distances**2 / np.sum(distances**2)\n",
    "        next_centroid_idx = np.random.choice(np.arange(len(vectors)), p=probabilities)\n",
    "        centroids[i] = vectors[next_centroid_idx]\n",
    "    return centroids\n",
    "    \n",
    "def calc_k_means_clusters(vectors, n_clusters, max_iter=100):\n",
    "    \"\"\"\n",
    "    Calculate k-means-plus-plus clusters\n",
    "    :param n_clusters: The number of clusters\n",
    "    :param max_iter: Max iterations number\n",
    "    :return: The centroids, the vectors divided into clusters, the vector ids divided into clusters\n",
    "    \"\"\"\n",
    "    iter = 0\n",
    "    centroids = initialize_k_means_pp(vectors, n_clusters)\n",
    "    prev_centroids = centroids\n",
    "    centroids = update_k_means_centroids(vectors, centroids)\n",
    "    while iter < max_iter and not np.array_equal(centroids, prev_centroids):\n",
    "        prev_centroids = centroids\n",
    "        centroids = update_k_means_centroids(vectors, centroids)\n",
    "        iter += 1\n",
    "\n",
    "    clusters_vectors, clusters_vector_ids = separate_to_clusters(vectors, centroids)\n",
    "    \n",
    "    return centroids, clusters_vectors, clusters_vector_ids\n",
    "\n",
    "\n",
    "def custom_indexing_algorithm(index_vectors, dim, n_clusters = 8):\n",
    "    \"\"\"\n",
    "    This function builds an index from scratch.\n",
    "    Args:\n",
    "        index_vectors: An array of shape (n_index, dim) containing the index vectors.\n",
    "        dim: The dimensionality of the vectors.\n",
    "    Returns:\n",
    "        An index.\n",
    "    \"\"\"\n",
    "    centroids, clusters_vectors, clusters_vector_ids = calc_k_means_clusters(index_vectors, n_clusters)\n",
    "    return centroids, clusters_vectors, clusters_vector_ids\n",
    "\n",
    "\n",
    "def custom_index_search(query_vectors, index, k):\n",
    "    \"\"\"\n",
    "    This function searches over the custom index.\n",
    "    Args:\n",
    "        query_vectors: An array of shape (n_queries, dim) containing the query vectors.\n",
    "        index: The custom index.\n",
    "        k: The number of nearest neighbors to retrieve.\n",
    "    \"\"\"\n",
    "    centroids, clusters_vectors, clusters_vector_ids = index\n",
    "    query_centroid_distances = np.linalg.norm(query_vectors[:, np.newaxis] - centroids, axis=2)\n",
    "    labels = np.argmin(query_centroid_distances, axis=1)\n",
    "    \n",
    "    ann_lists = []\n",
    "    \n",
    "    for query_vector, label in zip(query_vectors, labels):\n",
    "        cluster_index_vectors = clusters_vectors[label]\n",
    "        cluster_index_vectors_ids = clusters_vector_ids[label]\n",
    "        \n",
    "        distances = np.linalg.norm(cluster_index_vectors - query_vector, axis=1)\n",
    "        ann_lists.append(cluster_index_vectors_ids[np.argsort(distances)[:k]])\n",
    "        \n",
    "    return np.array(ann_lists)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "a50f4b92f2ec12fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:29.611584Z",
     "start_time": "2024-06-29T09:48:29.602579Z"
    }
   },
   "source": [
    "# Add hyperparameters here (if needed)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "ef371ecd242846db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:32.196969Z",
     "start_time": "2024-06-29T09:48:29.616591Z"
    }
   },
   "source": [
    "%%time\n",
    "custom_index = custom_indexing_algorithm(index_vectors, dim)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.56 s\n",
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "1c40c61275a3d001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:34.500997Z",
     "start_time": "2024-06-29T09:48:32.201974Z"
    }
   },
   "source": [
    "%%time\n",
    "custom_index_ann = custom_index_search(query_vectors, custom_index, k)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.28 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "3ddba190c55cd0af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:34.533011Z",
     "start_time": "2024-06-29T09:48:34.502996Z"
    }
   },
   "source": "print(f\"recall@10 for custom_index_search: {compute_recall_at_k(gt_nn, custom_index_ann, k)}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@10 for custom_index_search: 1.0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a737476715db3ddb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
