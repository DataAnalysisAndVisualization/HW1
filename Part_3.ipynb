{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cohere\n",
    "import numpy as np\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:32:00.286455Z",
     "start_time": "2024-06-29T12:31:56.119144Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "COHERE_API_KEY =\"bCicpvvKIFV8VV9bpC1ITwjYa6rjLeOPrwz6HVkm\"\n",
    "PINECONE_API_KEY = \"198559e6-23b6-49b3-b1ff-acc8ee2e6340\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:32:05.056572Z",
     "start_time": "2024-06-29T12:32:05.039571Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:32:22.452469Z",
     "start_time": "2024-06-29T12:32:12.915870Z"
    }
   },
   "source": [
    "#First lets write a query for the LLM\n",
    "query = \"How many people served as U.S. president between 1880 and 2000?\"\n",
    "\n",
    "co = cohere.Client(api_key=COHERE_API_KEY)\n",
    "response = co.chat(\n",
    "        model='command-r-plus',\n",
    "        message=query,\n",
    "    )\n",
    "response.text"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There were 21 U.S. presidents who served between 1880 and 2000. They are, in order of their presidency:\\n\\n1. Rutherford B. Hayes (1877-1881)\\n2. James A. Garfield (1881)\\n3. Chester A. Arthur (1881-1885)\\n4. Grover Cleveland (1885-1889)\\n5. Benjamin Harrison (1889-1893)\\n6. Grover Cleveland (1893-1897)\\n7. William McKinley (1897-1901)\\n8. Theodore Roosevelt (1901-1909)\\n9. William Howard Taft (1909-1913)\\n10. Woodrow Wilson (1913-1921)\\n11. Warren G. Harding (1921-1923)\\n12. Calvin Coolidge (1Multiplier,923-1929)\\n13. Herbert Hoover (1929-1933)\\n14. Franklin D. Roosevelt (1933-1945)\\n15. Harry S. Truman (1945-1953)\\n16. Dwight D. Eisenhower (1953-1961)\\n17. John F. Kennedy (1961-1963)\\n18. Lyndon B. Johnson (1963-1969)\\n19. Richard Nixon (1969-1974)\\n20. Gerald Ford (1974-1977)\\n21. Jimmy Carter (1977-1981)\\n22. Ronald Reagan (1981-1989)\\n23. George H.W. Bush (1989-1993)\\n24. Bill Clinton (1993-2001)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = load_dataset('wikitext', 'wikitext-2-raw-v1')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:32:40.364797Z",
     "start_time": "2024-06-29T12:32:22.457465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebce911fff27485e9a8b103620b31e2c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "011c901f6ee44f87a8210351d0723d20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca2de3096ba240b4b3c54f66f14dc74f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "811486aa189b4ba5bd3c70d00666b88b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c9323309fe746268d256e73fcf7bb6e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b968a1684314aaeb1a6fdc2f72f8b5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c059d01ab32b49e1a2468c5772749925"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "EMBEDDING_MODEL = 'all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:32:54.252250Z",
     "start_time": "2024-06-29T12:32:40.368790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "151fd0696bf046bb99f0c404d42a4d15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94022d03696342d2bb229a2c891aa6c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd60805a874b4772b1937cd61cc2b4b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84246cbbbc4c4a7f8c7c218e8e475ebb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5dda5e6caf7742c1bdce5e4ea595cc95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4274a1a74b5d49c68c5b740c785299d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d06a46e32a174dbf803203e53f887881"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7570fe946a1f45d0a8d80163469b222e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21336221dcf94676a998736c7ceb33e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de07f1fc2dbb4f7898782a13fc7dee2a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "581cbff66cb346b089623302ceca4b31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "def load_and_embedd_dataset(\n",
    "        dataset_path: str = 'wikitext',\n",
    "        dataset_name: str = 'wikitext-2-raw-v1',\n",
    "        split: str = 'train',\n",
    "        model: SentenceTransformer = SentenceTransformer('all-MiniLM-L6-v2'),\n",
    "        text_field: str = 'text',\n",
    "        rec_num: int = 400\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Load a dataset and embedd the text field using a sentence-transformer model\n",
    "    Args:\n",
    "        dataset_name: The name of the dataset to load\n",
    "        split: The split of the dataset to load\n",
    "        model: The model to use for embedding\n",
    "        text_field: The field in the dataset that contains the text\n",
    "        rec_num: The number of records to load and embedd\n",
    "    Returns:\n",
    "        tuple: A tuple containing the dataset and the embeddings\n",
    "    \"\"\"\n",
    "    print(\"Loading and embedding the dataset\")\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(dataset_path, dataset_name, split=split)\n",
    "\n",
    "    # Embed the first `rec_num` rows of the dataset\n",
    "    embeddings = model.encode(dataset[text_field][:rec_num])\n",
    "\n",
    "    print(\"Done!\")\n",
    "    return dataset, embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:42:13.579785Z",
     "start_time": "2024-06-29T12:42:08.613597Z"
    }
   },
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_path = 'wikitext'\n",
    "dataset_name = 'wikitext-2-raw-v1'\n",
    "\n",
    "dataset, embeddings = load_and_embedd_dataset(\n",
    "    dataset_path=dataset_path,\n",
    "    dataset_name=dataset_name,\n",
    "    rec_num=400,\n",
    "    model=model,\n",
    ")\n",
    "shape = embeddings.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:45:11.218800Z",
     "start_time": "2024-06-29T12:44:33.698911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and embedding the dataset\n",
      "Done!\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "pd_dataset = dataset.to_pandas()\n",
    "pd_dataset.head(7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T13:04:15.310212Z",
     "start_time": "2024-06-29T13:04:15.171215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text\n",
       "0                                                   \n",
       "1                     = Valkyria Chronicles III = \\n\n",
       "2                                                   \n",
       "3   Senjō no Valkyria 3 : Unrecorded Chronicles (...\n",
       "4   The game began development in 2010 , carrying...\n",
       "5   It met with positive sales in Japan , and was...\n",
       "6                                                   "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>= Valkyria Chronicles III = \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senjō no Valkyria 3 : Unrecorded Chronicles (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The game began development in 2010 , carrying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It met with positive sales in Japan , and was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"The embeddings shape: {embeddings.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:47:07.078691Z",
     "start_time": "2024-06-29T12:47:06.969692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embeddings shape: (400, 384)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "def create_pinecone_index(\n",
    "        index_name: str,\n",
    "        dimension: int,\n",
    "        metric: str = 'cosine',\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a pinecone index if it does not exist\n",
    "    Args:\n",
    "        index_name: The name of the index\n",
    "        dimension: The dimension of the index\n",
    "        metric: The metric to use for the index\n",
    "    Returns:\n",
    "        Pinecone: A pinecone object which can later be used for upserting vectors and connecting to VectorDBs\n",
    "    \"\"\"\n",
    "    from pinecone import Pinecone, ServerlessSpec\n",
    "    print(\"Creating a Pinecone index...\")\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "    if index_name not in existing_indexes:\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=dimension,\n",
    "            # Remember! It is crucial that the metric you will use in your VectorDB will also be a metric your embedding\n",
    "            # model works well with!\n",
    "            metric=metric,\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"\n",
    "            )\n",
    "        )\n",
    "    print(\"Done!\")\n",
    "    return pc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:47:24.793038Z",
     "start_time": "2024-06-29T12:47:24.749043Z"
    }
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "INDEX_NAME = 'cnn-dailymail'\n",
    "\n",
    "# Create the vector database\n",
    "# We are passing the index_name and the size of our embeddings\n",
    "pc = create_pinecone_index(INDEX_NAME, shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:47:35.272745Z",
     "start_time": "2024-06-29T12:47:28.692851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Pinecone index...\n",
      "Done!\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "def upsert_vectors(\n",
    "        index: Pinecone,\n",
    "        embeddings: np.ndarray,\n",
    "        dataset: dict,\n",
    "        text_field: str = 'text',\n",
    "        batch_size: int = 128\n",
    "):\n",
    "    \"\"\"\n",
    "    Upsert vectors to a pinecone index\n",
    "    Args:\n",
    "        index: The pinecone index object\n",
    "        embeddings: The embeddings to upsert\n",
    "        dataset: The dataset containing the metadata\n",
    "        batch_size: The batch size to use for upserting\n",
    "    Returns:\n",
    "        An updated pinecone index\n",
    "    \"\"\"\n",
    "    print(\"Upserting the embeddings to the Pinecone index...\")\n",
    "    shape = embeddings.shape\n",
    "\n",
    "    ids = [str(i) for i in range(shape[0])]\n",
    "    meta = [{text_field: text} for text in dataset[text_field]]\n",
    "\n",
    "    # create list of (id, vector, metadata) tuples to be upserted\n",
    "    to_upsert = list(zip(ids, embeddings, meta))\n",
    "\n",
    "    for i in tqdm(range(0, shape[0], batch_size)):\n",
    "        i_end = min(i + batch_size, shape[0])\n",
    "        index.upsert(vectors=to_upsert[i:i_end])\n",
    "    return index\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:48:16.697448Z",
     "start_time": "2024-06-29T12:48:16.659864Z"
    }
   },
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": [
    "# Upsert the embeddings to the Pinecone index\n",
    "index = pc.Index(INDEX_NAME)\n",
    "index_upserted = upsert_vectors(index, embeddings, dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:48:32.030416Z",
     "start_time": "2024-06-29T12:48:18.588615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting the embeddings to the Pinecone index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.98s/it]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "index.describe_index_stats()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:49:24.447935Z",
     "start_time": "2024-06-29T12:49:24.153927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 400}},\n",
       " 'total_vector_count': 400}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": [
    "def augment_prompt(\n",
    "        query: str,\n",
    "        model: SentenceTransformer = SentenceTransformer('all-MiniLM-L6-v2'),\n",
    "        index=None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Augment the prompt with the top 3 results from the knowledge base\n",
    "    Args:\n",
    "        query: The query to augment\n",
    "        index: The vectorstore object\n",
    "    Returns:\n",
    "        str: The augmented prompt\n",
    "    \"\"\"\n",
    "    results = [float(val) for val in list(model.encode(query))]\n",
    "\n",
    "    # get top 3 results from knowledge base\n",
    "    query_results = index.query(\n",
    "        vector=results,\n",
    "        top_k=3,\n",
    "        include_values=True,\n",
    "        include_metadata=True\n",
    "    )['matches']\n",
    "    text_matches = [match['metadata']['text'] for match in query_results]\n",
    "\n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\\n\".join(text_matches)\n",
    "\n",
    "    # feed into an augmented prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "    If the answer is not included in the source knowledge - say that you don't know.\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt, source_knowledge"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:55:59.527913Z",
     "start_time": "2024-06-29T12:55:56.221404Z"
    }
   },
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"Who sung the opening theme in Valkyria Chronicles III?\"\n",
    "\n",
    "co = cohere.Client(api_key=COHERE_API_KEY)\n",
    "response = co.chat(\n",
    "        model='command-r-plus',\n",
    "        message=query,\n",
    "    )\n",
    "print(\"Original response:\")\n",
    "print(response.text)\n",
    "print('-------------------------------------------------------------------------------------------------')\n",
    "\n",
    "augmented_prompt, source_knowledge = augment_prompt(query, model=model, index=index)\n",
    "response = co.chat(\n",
    "        model='command-r-plus',\n",
    "        message=augmented_prompt,\n",
    "    )\n",
    "print(\"Augmented response:\")\n",
    "print(response.text)\n",
    "print('-------------------------------------------------------------------------------------------------')\n",
    "print(\"Source knowledge:\")\n",
    "print(source_knowledge)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T13:24:14.635151Z",
     "start_time": "2024-06-29T13:24:11.628285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original response:\n",
      "*Valkyria Chronicles III* is an anime that aired in 2011 as part of the *Valkyria* franchise. The opening theme song for the series is called “Blue Star” and it is sung by Japanese singer and voice actress Hitomi Harada.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Augmented response:\n",
      "May'n\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Source knowledge:\n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
      "\n",
      "\n",
      " = Valkyria Chronicles III = \n",
      "\n",
      "\n",
      " The music was composed by Hitoshi Sakimoto , who had also worked on the previous Valkyria Chronicles games . When he originally heard about the project , he thought it would be a light tone similar to other Valkyria Chronicles games , but found the themes much darker than expected . An early theme he designed around his original vision of the project was rejected . He redid the main theme about seven times through the music production due to this need to reassess the game . The main theme was initially recorded using orchestra , then Sakimoto removed elements such as the guitar and bass , then adjusted the theme using a synthesizer before redoing segments such as the guitar piece on their own before incorporating them into the theme . The rejected main theme was used as a hopeful tune that played during the game 's ending . The battle themes were designed around the concept of a \" modern battle \" divorced from a fantasy scenario by using modern musical instruments , constructed to create a sense of atonality . While Sakimoto was most used to working with synthesized music , he felt that he needed to incorporate live instruments such as orchestra and guitar . The guitar was played by Mitsuhiro Ohta , who also arranged several of the later tracks . The game 's opening theme song , \" If You Wish for ... \" ( もしも君が願うのなら , Moshimo Kimi ga Negauno Nara ) , was sung by Japanese singer May 'n . Its theme was the reason soldiers fought , in particular their wish to protect what was precious to them rather than a sense of responsibility or duty . Its lyrics were written by Seiko Fujibayashi , who had worked on May 'n on previous singles . \n",
      "\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T13:24:24.736176Z",
     "start_time": "2024-06-29T13:24:23.561182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"Who sung the opening theme in Valkyria Chronicles III? If the answer is not included in the source knowledge - say that you don't know.\"\n",
    "\n",
    "co = cohere.Client(api_key=COHERE_API_KEY)\n",
    "response = co.chat(\n",
    "        model='command-r-plus',\n",
    "        message=query,\n",
    "    )\n",
    "print(\"Original response:\")\n",
    "print(response.text)\n",
    "print('-------------------------------------------------------------------------------------------------')\n",
    "\n",
    "augmented_prompt, source_knowledge = augment_prompt(query, model=model, index=index)\n",
    "response = co.chat(\n",
    "        model='command-r-plus',\n",
    "        message=augmented_prompt,\n",
    "    )\n",
    "print(\"Augmented response:\")\n",
    "print(response.text)\n",
    "print('-------------------------------------------------------------------------------------------------')\n",
    "print(\"Source knowledge:\")\n",
    "print(source_knowledge)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original response:\n",
      "I don't know.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Augmented response:\n",
      "May'n\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Source knowledge:\n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
      "\n",
      "\n",
      " = Valkyria Chronicles III = \n",
      "\n",
      "\n",
      " The music was composed by Hitoshi Sakimoto , who had also worked on the previous Valkyria Chronicles games . When he originally heard about the project , he thought it would be a light tone similar to other Valkyria Chronicles games , but found the themes much darker than expected . An early theme he designed around his original vision of the project was rejected . He redid the main theme about seven times through the music production due to this need to reassess the game . The main theme was initially recorded using orchestra , then Sakimoto removed elements such as the guitar and bass , then adjusted the theme using a synthesizer before redoing segments such as the guitar piece on their own before incorporating them into the theme . The rejected main theme was used as a hopeful tune that played during the game 's ending . The battle themes were designed around the concept of a \" modern battle \" divorced from a fantasy scenario by using modern musical instruments , constructed to create a sense of atonality . While Sakimoto was most used to working with synthesized music , he felt that he needed to incorporate live instruments such as orchestra and guitar . The guitar was played by Mitsuhiro Ohta , who also arranged several of the later tracks . The game 's opening theme song , \" If You Wish for ... \" ( もしも君が願うのなら , Moshimo Kimi ga Negauno Nara ) , was sung by Japanese singer May 'n . Its theme was the reason soldiers fought , in particular their wish to protect what was precious to them rather than a sense of responsibility or duty . Its lyrics were written by Seiko Fujibayashi , who had worked on May 'n on previous singles . \n",
      "\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"When did Raphael Tuck buy four of Barker's 'little drawings'?\"\n",
    "\n",
    "co = cohere.Client(api_key=COHERE_API_KEY)\n",
    "response = co.chat(\n",
    "        model='command-r-plus',\n",
    "        message=query,\n",
    "    )\n",
    "print(\"Original response:\")\n",
    "print(response.text)\n",
    "print('-------------------------------------------------------------------------------------------------')\n",
    "\n",
    "augmented_prompt, source_knowledge = augment_prompt(query, model=model, index=index)\n",
    "response = co.chat(\n",
    "        model='command-r-plus',\n",
    "        message=augmented_prompt,\n",
    "    )\n",
    "print(\"Augmented response:\")\n",
    "print(response.text)\n",
    "\n",
    "print('-------------------------------------------------------------------------------------------------')\n",
    "print(\"Source knowledge:\")\n",
    "print(source_knowledge)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T13:13:50.971557Z",
     "start_time": "2024-06-29T13:13:49.258558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original response:\n",
      "Raphael Tuck bought four of Barker's \"little drawings\" in 1866.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Augmented response:\n",
      "In 1911, Raphael Tuck & Sons bought four of Barker's \"little drawings.\"\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Source knowledge:\n",
      " In 1911 , Raphael Tuck & Sons bought four of Barker 's \" little drawings \" for half a sovereign , and published them as postcards . In October 1911 , she won second prize in the Croydon Art Society 's poster competition , and shortly afterward was elected the youngest member of the Society . The art critic for the Croydon Advertiser remarked , \" Her drawings show a remarkable freedom of spirit . She has distinct promise . \" \n",
      "\n",
      "\n",
      " Following her father ’ s death in June 1912 , the seventeen @-@ year @-@ old Barker submitted art and poetry to My Magazine , Child ’ s Own , Leading Strings , and Raphael Tuck annuals in an effort to support both her mother and sister . Her sister Dorothy taught kindergarten in two private schools before opening a kindergarten at home . She brought in some money for the family 's support while supervising the household . \n",
      "\n",
      "\n",
      " Barker was equally proficient in watercolour , pen and ink , oils , and pastels . Kate Greenaway and the Pre @-@ Raphaelites were the principal influences on her work . She claimed to paint instinctively and rejected artistic theories . Barker died in 1973 . Though she published Flower Fairy books with spring , summer , and autumn themes , it wasn 't until 1985 that a winter collection was assembled from her remaining work and published posthumously . \n",
      "\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"When did Columbus have the best chance of receiving the first overall pick?\"\n",
    "\n",
    "co = cohere.Client(api_key=COHERE_API_KEY)\n",
    "response = co.chat(\n",
    "        model='command-r-plus',\n",
    "        message=query,\n",
    "    )\n",
    "print(\"Original response:\")\n",
    "print(response.text)\n",
    "print('-------------------------------------------------------------------------------------------------')\n",
    "\n",
    "augmented_prompt, source_knowledge = augment_prompt(query, model=model, index=index)\n",
    "response = co.chat(\n",
    "        model='command-r-plus',\n",
    "        message=augmented_prompt,\n",
    "    )\n",
    "print(\"Augmented response:\")\n",
    "print(response.text)\n",
    "\n",
    "print('-------------------------------------------------------------------------------------------------')\n",
    "print(\"Source knowledge:\")\n",
    "print(source_knowledge)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T13:18:20.386109Z",
     "start_time": "2024-06-29T13:18:13.213389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original response:\n",
      "The Columbus Blue Jackets had the best chance of receiving the first overall pick in the 2021 NHL Entry Draft. They had a 12.5% chance of winning the draft lottery and selecting first overall but ultimately lost out to the Buffalo Sabres, who won the lottery and jumped up from the sixth spot.\n",
      "\n",
      "The 2021 draft was considered to have a very talented pool of prospects, with players like Owen Power, Matthew Beniers, and Mason McTavish projected to be selected early on. The Blue Jackets ended up with the fifth overall pick and selected defenseman Kent Johnson.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Augmented response:\n",
      "Columbus had the best chance of receiving the first overall pick in the 2012 NHL Entry Draft lottery.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Source knowledge:\n",
      " Finishing with the worst record in the NHL , Columbus had the best chance of receiving the first overall pick in the 2012 draft . With the NHL 's weighted draft lottery the Blue Jackets had a 48 @.@ 2 % chance of drafting first overall . However , the lottery was won by the Edmonton Oilers , who proceeded to leapfrog Columbus and secure the number one draft pick for a third consecutive year . It was the fifth time that the Blue Jackets were dropped one draft position in the franchise 's 12 lottery participations . \n",
      "\n",
      "\n",
      " Two weeks prior to the NHL trade deadline , Columbus announced that unlike earlier in the season , they would listen to trade proposals involving Rick Nash , though they were not actively shopping him . Howson stated that the team was open to all options for improving the team , including trading Nash . Speculation was that in return for Nash the Blue Jackets would ask for a \" combination of young , proven players , high @-@ end prospects and draft picks . \" Leading up to the trade deadline , the Blue Jackets dealt Antoine Vermette to the Phoenix Coyotes for two draft picks and goaltender Curtis McElhinney . Despite being injured at the time , the acquisition of McElhinney was believed to give Columbus the flexibility to trade Curtis Sanford . The following day , on February 23 , Columbus traded Jeff Carter to the Kings . In the deal , Columbus acquired defenseman Jack Johnson and a first @-@ round draft pick ; the team was given the choice of taking the pick in either 2012 or 2013 . At the deadline , Columbus was unable to come to terms on a deal involving Nash , but they did make one more move ; they sent center Samuel Pahlsson to the Vancouver Canucks in exchange for two fourth @-@ round draft picks and minor league defenseman Taylor Ellington . Following the trade deadline , Howson announced that the team had attempted to trade Nash at the player 's request . Nash stated that he had requested the trade after being informed that the franchise was going into another rebuilding phase . He further noted that he felt that he \" could be a huge part of that towards bringing assets in , \" and in his view \" it was the best thing for the team , the organization , and personally for [ his ] career . \" After the personnel changes , the Blue Jackets closed out the month with a three @-@ game losing streak . \n",
      "\n",
      "\n",
      " The 2011 – 12 Columbus Blue Jackets season was the team 's 12th season in the National Hockey League ( NHL ) . The Blue Jackets ' record of 29 – 46 – 7 [ note 1 ] was the worst record in the NHL for 2011 – 12 and the first time in franchise history they finished in last place . It also marked the third straight year that they missed the playoffs . Consequently , they had the best chance to receive the first overall selection in the 2012 NHL Entry Draft lottery , but lost out to the Edmonton Oilers and received the second pick instead . \n",
      "\n"
     ]
    }
   ],
   "execution_count": 64
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
